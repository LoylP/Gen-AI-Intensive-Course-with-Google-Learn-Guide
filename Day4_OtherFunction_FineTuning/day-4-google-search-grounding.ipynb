{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-4-google-search-grounding.ipynb","toc_visible":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Day 4 - Google Search grounding with the Gemini API","metadata":{"id":"q-mcOl0JY8Xg"}},{"cell_type":"markdown","source":"## API: Get set up\n\nThis section requires an API key with billing enabled. Start by installing and importing the Gemini API Python SDK.","metadata":{"id":"Qcyq976Gbwpo"}},{"cell_type":"code","source":"%pip install -q -U 'google-generativeai>=0.8.3'","metadata":{"id":"1ZLC4ORSbqme","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import google.generativeai as genai\nfrom IPython.display import Markdown, HTML, display","metadata":{"id":"FNkHtOAmbt2B","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"id":"8NAmACYHb5DK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explore available models\n\nSearch grounding is a tool available in the `-002` series of models. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about different model capabilities on [the models page](https://ai.google.dev/gemini-api/docs/models/gemini).","metadata":{"id":"Rvre6fOrcHi2"}},{"cell_type":"code","source":"for model in genai.list_models():\n    if \"002\" in model.name:\n        print(model.name)","metadata":{"id":"p6G2H6N4dT02","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Search without grounding","metadata":{"id":"HW5RVNUierrQ"}},{"cell_type":"code","source":"# Ask for information without search grounding.\nmodel = genai.GenerativeModel(\"models/gemini-1.5-flash-002\")\n\nresponse = model.generate_content(\"Which country won the world cup most recently?\")\nrc = response.candidates[0]\n\nMarkdown(rc.content.parts[0].text)","metadata":{"id":"JZmdaOlVfCgd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Use search grounding","metadata":{}},{"cell_type":"code","source":"# And now re-run the same query with search grounding enabled.\nmodel = genai.GenerativeModel(\n    \"gemini-1.5-flash-002\",\n    tools=\"google_search_retrieval\")\n\nresponse = model.generate_content(\"Which country won the world cup most recently?\")\nrc = response.candidates[0]\n\nMarkdown(rc.content.parts[0].text)","metadata":{"id":"i7jqG3nww6kU","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The most recent country to win the FIFA World Cup is Argentina, who won the tournament in 2022.[1][2][3][4][5] They defeated France 4-2 in a penalty shootout after the game was tied 3-3 after extra time. This was Argentina's third World Cup title.[1][4][5][6]\n  \r\nSearch Source:l\n* wikipedia.org\n* thehighlightsapp.com\n* careerpower.in\n* nbcsports.com\n* statista.com\n* wikipedia.org\nedia.org","metadata":{}},{"cell_type":"markdown","source":"### Response metadata\n\nWhen search grounding is used, the model returns extra metadata that includes links to search suggestions, supporting documents and information on how the supporting documents were used.\n\nEach \"grounding chunk\" represents information retrieved from Google Search that was used in the grounded generation request. Following the URI will take you to the source.","metadata":{"id":"SJc_0FFBgoiJ"}},{"cell_type":"code","source":"chunks = rc.grounding_metadata.grounding_chunks\nfor chunk in chunks:\n    print(chunk)","metadata":{"id":"2P7IYMcvxtcy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As part of the response, there is a standalone styled HTML content block that you use to link back to relevant search suggestions related to the generation.","metadata":{"id":"ziYb2Fkjzwwx"}},{"cell_type":"code","source":"HTML(rc.grounding_metadata.search_entry_point.rendered_content)","metadata":{"id":"DQAgIGJmfxqC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"supports = rc.grounding_metadata.grounding_supports\nfor support in supports:\n    print(support)","metadata":{"id":"sHg9Yq9U0r89","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import io\n\nmarkdown_buffer = io.StringIO()\n\n# Print the text with footnote markers.\nmarkdown_buffer.write(\"Supported text:\\n\\n\")\nfor support in supports:\n    markdown_buffer.write(\" * \")\n    markdown_buffer.write(\n        response.text[support.segment.start_index : support.segment.end_index]\n    )\n\n    for i in support.grounding_chunk_indices:\n        chunk = chunks[i].web\n        markdown_buffer.write(f\"<sup>[{i+1}]</sup>\")\n\n    markdown_buffer.write(\"\\n\\n\")\n\n\n# And print the footnotes.\nmarkdown_buffer.write(\"Citations:\\n\\n\")\nfor i, chunk in enumerate(chunks, start=1):\n    markdown_buffer.write(f\"* {i}: [{chunk.web.title}]({chunk.web.uri})\\n\")\n\n\nMarkdown(markdown_buffer.getvalue())","metadata":{"id":"9_dEINt43C62","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Dynamic grounding\n\nIn a context where you may not know in advance whether to enable search grounding or not, you can provide the model with a threshold over which it will use search grounding. This is helpful in conversational contexts, where not every turn of conversation requires search data to support a response.\n\nIf you know whether to enable Search for any given chat turn, you can provide the tool explicitly.\n\n\n<table align=left>\n  <td>\n    <a target=\"_blank\" href=\"https://aistudio.google.com/prompts/1VBx_R16kNWa8g7lpLxQPx_08sFtd7tcd\"><img src=\"https://ai.google.dev/site-assets/images/marketing/home/icon-ais.png\" style=\"height: 24px\" height=24/> Open in AI Studio</a>\n  </td>\n</table>","metadata":{"id":"suX0M2By8LIN"}},{"cell_type":"code","source":"nosearch_model = genai.GenerativeModel(\"gemini-1.5-flash-002\")\nchat = nosearch_model.start_chat()\n\n# No search grounding.\nr = chat.send_message(\"Hello friendly chatbot!\")\n\n# Enable search for just this turn.\nr = chat.send_message(\n    \"Who took home the 2023 cricket world cup?\", tools=\"google_search_retrieval\"\n)\n\nMarkdown(r.text)","metadata":{"id":"6FLf92417p_4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"HTML(r.candidates[0].grounding_metadata.search_entry_point.rendered_content)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Or you can let the Gemini API calculate a likelihood that the response needs search backing, and define the threshold to use.","metadata":{"id":"6nSCaNfL9wSL"}},{"cell_type":"code","source":"# The dynamic retrieval score is a probability, so the threshold\n# must also be bound by [0, 1].\nsearch_config = {\n    \"dynamic_retrieval_config\": {\"mode\": \"MODE_DYNAMIC\", \"dynamic_threshold\": 0.5}\n}\n\nmaybe_search_model = genai.GenerativeModel(\n    \"gemini-1.5-flash-002\", tools={\"google_search_retrieval\": search_config}\n)\n\nchat = maybe_search_model.start_chat()\n\nr = chat.send_message(\"Hello friendly chatbot!\")\nrc = r.candidates[0]\nscore = rc.grounding_metadata.retrieval_metadata.google_search_dynamic_retrieval_score\nprint(f\"First turn: {score=}\")\n\nr = chat.send_message(\"Who took home the 2023 cricket world cup?\")\nrc = r.candidates[0]\nscore = rc.grounding_metadata.retrieval_metadata.google_search_dynamic_retrieval_score\nprint(f\"Second turn: {score=}\")\nprint()\n\ndisplay(Markdown(r.text))","metadata":{"id":"WdqdYOND98M4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"HTML(rc.grounding_metadata.search_entry_point.rendered_content)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}